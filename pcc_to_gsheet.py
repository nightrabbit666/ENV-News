import time
import os
import sys
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# --- è¨­å®šå€ ---

# 1. æœå°‹æ¸…å–®
# æ¨™æ¡ˆåç¨±é—œéµå­—
KEYWORDS = ["è³‡æºå›æ”¶", "åˆ†é¸", "ç´°åˆ†é¸å ´", "ç´°åˆ†é¸å» ", "ç´°åˆ†é¡", "å»¢æ£„ç‰©"]
# æ©Ÿé—œåç¨±é—œéµå­—
ORG_KEYWORDS = ["è³‡æºå¾ªç’°ç½²", "ç’°å¢ƒç®¡ç†ç½²"]

# 2. Google Sheets è¨­å®š
# è‡ªå‹•æŠ“å–ç•¶å‰ç›®éŒ„ä¸‹çš„ key.json (ç”± GitHub Actions ç”¢ç”Ÿ)
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
JSON_KEY_FILE = os.path.join(BASE_DIR, 'key.json')

# âš ï¸ è«‹ç¢ºèªæ‚¨çš„è©¦ç®—è¡¨ç¶²å€èˆ‡å·¥ä½œè¡¨åç¨±
SHEET_URL = 'https://docs.google.com/spreadsheets/d/1oJlYFwsipBg1hGMuUYuOWen2jlX19MDJomukvEoahUE/edit' 
WORKSHEET_NAME = 'news'

# 3. ç›®æ¨™ç¶²å€ (åŸºæœ¬æŸ¥è©¢é¦–é  - æ‚¨æŒ‡å®šçš„æ­£ç¢ºç¶²å€)
TARGET_URL = "https://web.pcc.gov.tw/prkms/tender/common/basic/indexTenderBasic"

def init_driver():
    """åˆå§‹åŒ–ç€è¦½å™¨"""
    chrome_options = Options()
    
    # âš ï¸ã€é—œéµä¿®æ­£ã€‘å¼·åˆ¶é–‹å•Ÿç„¡é ­æ¨¡å¼
    # é€™è¡Œçµ•å°ä¸èƒ½è¢«è¨»è§£æ‰ï¼Œå¦å‰‡ GitHub Actions æœƒç›´æ¥å ±éŒ¯ (NoneType error)
    chrome_options.add_argument("--headless") 
    
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36")
    
    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        return driver
    except Exception as e:
        print(f"âŒ ç€è¦½å™¨å•Ÿå‹•å¤±æ•—: {e}")
        # å¦‚æœç€è¦½å™¨æ²’å•Ÿå‹•æˆåŠŸï¼Œç›´æ¥çµæŸç¨‹å¼ï¼Œé¿å…å¾ŒçºŒå ±éŒ¯
        sys.exit(1)

def search_pcc(driver, keyword, search_type):
    """
    åŸ·è¡Œæœå°‹ (åŸºæœ¬æŸ¥è©¢ä»‹é¢å°ˆç”¨)
    search_type: "name" (æ¨™æ¡ˆåç¨±) / "org" (æ©Ÿé—œåç¨±)
    """
    print(f"\nğŸ” æ­£åœ¨æœå°‹ [{('æ©Ÿé—œ' if search_type=='org' else 'æ¨™æ¡ˆ')}]ï¼š{keyword} ...")
    
    try:
        driver.get(TARGET_URL)
        wait = WebDriverWait(driver, 20)

        # 1. é–å®šè¼¸å…¥æ¡† (äº’æ–¥é‚è¼¯ï¼šå¡«ä¸€å€‹ï¼Œæ¸…ç©ºå¦ä¸€å€‹)
        if search_type == "name":
            # å¡«å…¥ @æ¨™æ¡ˆåç¨±
            input_box = wait.until(EC.visibility_of_element_located((By.NAME, "tenderName")))
            # æ¸…ç©ºæ©Ÿé—œåç¨±
            driver.find_element(By.NAME, "orgName").clear()
        else:
            # å¡«å…¥ @æ©Ÿé—œåç¨±
            input_box = wait.until(EC.visibility_of_element_located((By.NAME, "orgName")))
            # æ¸…ç©ºæ¨™æ¡ˆåç¨±
            driver.find_element(By.NAME, "tenderName").clear()
            
        input_box.clear()
        input_box.send_keys(keyword)
        
        # 2. é»æ“Šã€ŒæŸ¥è©¢ã€æŒ‰éˆ• (ç´…æ¡†è™•)
        # é–å®š form è£¡é¢çš„æŸ¥è©¢æŒ‰éˆ•ï¼Œé¿å…é»åˆ°æ—é‚Šçš„å°å¹«æ‰‹
        search_btn = driver.find_element(By.CSS_SELECTOR, "input[name='search']")
        driver.execute_script("arguments[0].click();", search_btn)
        
        # 3. ç­‰å¾…çµæœ & åš´æ ¼éæ¿¾
        try:
            # ç­‰å¾…è¡¨æ ¼å‡ºç¾
            wait.until(EC.presence_of_element_located((By.CLASS_NAME, "tb_01")))
            
            # â˜… é—œéµæª¢æŸ¥ï¼šå¦‚æœç¶²é é¡¯ç¤ºã€Œç„¡ç¬¦åˆæ¢ä»¶è³‡æ–™ã€ï¼Œç›´æ¥è·³éï¼
            # é€™æ¨£å°±çµ•å°ä¸æœƒå»æŠ“åˆ°ä¸Šé¢çš„é¸å–®æŒ‰éˆ•
            page_text = driver.find_element(By.TAG_NAME, "body").text
            if "ç„¡ç¬¦åˆæ¢ä»¶è³‡æ–™" in page_text or "ç„¡è³‡æ–™" in page_text:
                print(f"   -> æŸ¥ç„¡è³‡æ–™ (è·³é)")
                return []
        except:
            print(f"   -> è¼‰å…¥è¶…æ™‚æˆ–ç„¡è¡¨æ ¼ (è·³é)")
            return []
        
        # 4. æŠ“å–è³‡æ–™ (ç²¾æº–æŠ“å–è¡¨æ ¼å…§å®¹)
        results = []
        rows = driver.find_elements(By.CSS_SELECTOR, ".tb_01 tbody tr")
        
        # åƒåœ¾æ¨™é¡Œé»‘åå–® (é›™é‡ä¿éšª)
        JUNK_TITLES = ["æ¨™æ¡ˆæŸ¥è©¢", "æ±ºæ¨™æŸ¥è©¢", "å…¨æ–‡æª¢ç´¢", "å…¬å‘Šæ—¥æœŸæŸ¥è©¢", "æ©Ÿé—œåç¨±æŸ¥è©¢"]

        for row in rows:
            cols = row.find_elements(By.TAG_NAME, "td")
            # æ¬„ä½æ•¸é‡æª¢æŸ¥ï¼šåŸºæœ¬æŸ¥è©¢è¡¨æ ¼é€šå¸¸æœ‰ 9 æ¬„
            if len(cols) < 7: continue
                
            try:
                # [1] æ©Ÿé—œåç¨±
                org_name = cols[1].text.strip()
                
                # [6] å…¬å‘Šæ—¥æœŸ
                date_str = cols[6].text.strip()
                
                # [2] æ¨™æ¡ˆåç¨±èˆ‡é€£çµ
                # é€™è£¡åŒæ™‚æœ‰ã€Œæ¡ˆè™Ÿã€è·Ÿã€Œåç¨±ã€ï¼Œæˆ‘å€‘ç”¨é•·åº¦åˆ¤æ–·æŠ“å‡ºåç¨±
                links_in_cell = cols[2].find_elements(By.TAG_NAME, "a")
                
                tender_name = ""
                tender_link = ""
                
                if links_in_cell:
                    # æ‰¾å‡ºæ–‡å­—æœ€é•·çš„é€£çµ (æ’é™¤çŸ­æ¡ˆè™Ÿ)
                    longest_link = max(links_in_cell, key=lambda x: len(x.text.strip()))
                    tender_name = longest_link.text.strip()
                    tender_link = longest_link.get_attribute("href")
                else:
                    # æ²’é€£çµå°±æŠ“ç´”æ–‡å­—
                    tender_name = cols[2].text.strip()

                # â˜… é˜²åƒåœ¾éæ¿¾å™¨
                # 1. å¦‚æœæ¨™é¡Œå¤ªçŸ­æˆ–ç©ºçš„ -> ä¸Ÿæ‰
                if not tender_name or len(tender_name) < 2: continue
                # 2. å¦‚æœæ¨™é¡Œæ˜¯é¸å–®æ–‡å­— -> ä¸Ÿæ‰
                if any(junk in tender_name for junk in JUNK_TITLES): continue

                results.append({
                    "Date": date_str,
                    "Title": tender_name,
                    "Link": tender_link,
                    "Tags": f"{('æ©Ÿé—œ' if search_type=='org' else 'æ¨™æ¡ˆ')}-{keyword}",
                    "Source": org_name
                })
            except:
                continue 
        
        print(f"   -> æˆåŠŸæ‰¾åˆ° {len(results)} ç­†")
        return results

    except Exception as e:
        print(f"   âŒ æœå°‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

def upload_to_gsheet(df):
    """ä¸Šå‚³è‡³ Google Sheets"""
    print("\nâ˜ï¸ æ­£åœ¨é€£ç·š Google Sheets...")
    
    if not os.path.exists(JSON_KEY_FILE):
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° key.jsonï¼è·¯å¾‘: {JSON_KEY_FILE}")
        return

    try:
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_name(JSON_KEY_FILE, scope)
        client = gspread.authorize(creds)
        
        sheet = client.open_by_url(SHEET_URL).worksheet(WORKSHEET_NAME)
        existing_data = sheet.get_all_records()
        existing_links = set(str(row['Link']) for row in existing_data if 'Link' in row)
        
        new_rows = []
        for index, row in df.iterrows():
            if str(row['Link']) not in existing_links:
                # æ¬„ä½é †åº: Date, Tags, Title, Link, Source
                row_data = [row['Date'], row['Tags'], row['Title'], row['Link'], row['Source']]
                new_rows.append(row_data)
                existing_links.add(str(row['Link']))
        
        if new_rows:
            sheet.append_rows(new_rows)
            print(f"âœ… æˆåŠŸä¸Šå‚³ {len(new_rows)} ç­†æ–°è³‡æ–™åˆ°é›²ç«¯ï¼")
        else:
            print("âš ï¸ æ²’æœ‰æ–°çš„ä¸é‡è¤‡è³‡æ–™éœ€ä¸Šå‚³ã€‚")
            
    except Exception as e:
        print(f"âŒ ä¸Šå‚³ Google Sheets å¤±æ•—: {e}")

def main():
    print("ğŸš€ å•Ÿå‹•æ”¿åºœæ¡è³¼ç¶²çˆ¬èŸ² (V15.0 é›²ç«¯ä¿®æ­£ç‰ˆ)...")
    driver = init_driver()
    all_data = []
    
    try:
        # 1. æœå°‹æ©Ÿé—œ
        print("\n--- æœå°‹æ©Ÿé—œåç¨± ---")
        for org in ORG_KEYWORDS:
            data = search_pcc(driver, org, search_type="org")
            all_data.extend(data)
            time.sleep(2)

        # 2. æœå°‹æ¨™æ¡ˆ
        print("\n--- æœå°‹æ¨™æ¡ˆé—œéµå­— ---")
        for kw in KEYWORDS:
            data = search_pcc(driver, kw, search_type="name")
            all_data.extend(data)
            time.sleep(2)
            
    finally:
        print("\nğŸ›‘ é—œé–‰ç€è¦½å™¨...")
        if driver:
            driver.quit()
        
    if all_data:
        df = pd.DataFrame(all_data)
        df.drop_duplicates(subset=['Link'], keep='first', inplace=True)
        print(f"\nğŸ“Š å…±æŠ“å–åˆ° {len(df)} ç­†è³‡æ–™ï¼Œæº–å‚™ä¸Šå‚³...")
        upload_to_gsheet(df)
    else:
        print("\nâŒ æœ¬æ¬¡åŸ·è¡Œæ²’æœ‰æ‰¾åˆ°ä»»ä½•æ¨™æ¡ˆã€‚")

if __name__ == "__main__":
    main()
